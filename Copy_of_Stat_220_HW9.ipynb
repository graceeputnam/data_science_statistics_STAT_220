{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7MhmR-jSBpz"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/drbob-richardson/stat220/blob/main/Assignments/Stat_220_HW9.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKYFIgmdARUH"
      },
      "source": [
        "**Problem 1** A number of measurements were collected for a large variety of cars in order to predict fuel efficiency of the car and to understand what factors significantly affect fuel efficiency. You can read in this data here\n",
        "cars = pd.read_csv(\"https://richardson.byu.edu/220/cars.csv\")\n",
        "More information on this data can be found here: https://code.datasciencedojo.com/datasciencedojo/datasets/tree/master/Auto%20MPG\n",
        "Your task is to build a model that we can use to determine important information about the relationship between fuel efficiency and the other factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvg_MhHjAZqf"
      },
      "source": [
        "Part a. Build and tune a linear regression model to predict the target variable, mpg or miles per gallon, using all the other variables besides car_name as predictors.  Tune the model so that only significant features remain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k3PHaISdAUql"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "cars = pd.read_csv(\"https://richardson.byu.edu/220/cars.csv\")\n",
        "\n",
        "X = cars.select_dtypes(include=[np.number]).drop('mpg', axis=1)\n",
        "y = cars['mpg']\n",
        "\n",
        "X_with_const = sm.add_constant(X)\n",
        "model = sm.OLS(y, X_with_const).fit()\n",
        "\n",
        "significant_vars = model.pvalues[model.pvalues < 0.05].index.tolist()\n",
        "if 'const' in significant_vars:\n",
        "    significant_vars.remove('const')\n",
        "\n",
        "X_sig = X[significant_vars]\n",
        "X_sig_const = sm.add_constant(X_sig)\n",
        "model_tuned = sm.OLS(y, X_sig_const).fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8VoX47_AgXF"
      },
      "source": [
        "Part b. You will likely find the variable weight significant. What is the confidence interval for the coefficient associated with weight?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i_eC2e_EAQsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1bd3bb-2955-4449-a157-f2c668460433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence interval for weight: [-0.0071, -0.0062]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ci = model_tuned.conf_int()\n",
        "weight_ci = ci.loc['weight']\n",
        "\n",
        "print(f\"Confidence interval for weight: [{weight_ci[0]:.4f}, {weight_ci[1]:.4f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz3rOU21AwhO"
      },
      "source": [
        "Part c. You are asked, how does weight affect fuel efficiency. Answer the question while providing some uncertainty to the answer (i.e. interpret the confidence interval)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weight has a negative effect on fuel efficiency. For every 1 pound increase in weight, we can expect mpg to decrease by between 0.0062 and 0.0071 miles per gallon. The confidence interval tells us that we can be about 95% sure that the true mpg decrease is inbetween 0.0062 and 0.0071 miles per gallon."
      ],
      "metadata": {
        "id": "NnB8LXNZ2m1R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppLJYyYQA9il"
      },
      "source": [
        "**Problem 2** Explore adding higher order terms into the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B04wUKHBBJW"
      },
      "source": [
        "Part a. Fit and tune a model that includes the interaction between weight and model_year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E7I7muUkBGOu"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_int = X.copy()\n",
        "X_int['weight_x_model_year'] = X['weight'] * X['model_year']\n",
        "\n",
        "X_int_const = sm.add_constant(X_int)\n",
        "model_int = sm.OLS(y, X_int_const).fit()\n",
        "\n",
        "sig_vars = model_int.pvalues[model_int.pvalues < 0.05].index.tolist()\n",
        "if 'const' in sig_vars:\n",
        "    sig_vars.remove('const')\n",
        "\n",
        "X_int_sig = X_int[sig_vars]\n",
        "X_int_sig_const = sm.add_constant(X_int_sig)\n",
        "model_int_tuned = sm.OLS(y, X_int_sig_const).fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naHu6GthBGle"
      },
      "source": [
        "Part b. Interpret this model, including the interactions, to a non-technical audience using no numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9J4QBRiBHa-"
      },
      "source": [
        "The model shows that heavier cars generally have worse fuel efficiency, but this effect also depends on the car's model year. For newer cars, the impact of weight on fuel efficiency is less severe than for older cars. Basically, becuase cars are now more modern the technology gets better at handling extra weight, so weight matters less for fuel efficiency in newer cars compared to older ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au8NpPr_BLeu"
      },
      "source": [
        "Part c. Examine using all higher order terms in the model. Using out of sample metrics, compare a model with no higher terms to a model with all higher order terms (no reducing the full model yet). Remember to keep car name out of the predictor set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q-OJKA8cBqm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24cb0677-0780-432e-b184-a8ab341cab5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No higher order terms: RMSE = 3.241, R² = 0.794\n",
            "All higher order terms: RMSE = 2.724, R² = 0.855\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "model_no_poly = sm.OLS(y_train, X_train_const).fit()\n",
        "y_pred_no_poly = model_no_poly.predict(X_test_const)\n",
        "rmse_no_poly = np.sqrt(mean_squared_error(y_test, y_pred_no_poly))\n",
        "r2_no_poly = r2_score(y_test, y_pred_no_poly)\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "X_train_poly_const = sm.add_constant(X_train_poly)\n",
        "X_test_poly_const = sm.add_constant(X_test_poly)\n",
        "model_all_poly = sm.OLS(y_train, X_train_poly_const).fit()\n",
        "y_pred_all_poly = model_all_poly.predict(X_test_poly_const)\n",
        "rmse_all_poly = np.sqrt(mean_squared_error(y_test, y_pred_all_poly))\n",
        "r2_all_poly = r2_score(y_test, y_pred_all_poly)\n",
        "\n",
        "print(f\"No higher order terms: RMSE = {rmse_no_poly:.3f}, R² = {r2_no_poly:.3f}\")\n",
        "print(f\"All higher order terms: RMSE = {rmse_all_poly:.3f}, R² = {r2_all_poly:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6P8fhB1Bq6f"
      },
      "source": [
        "Part d. Reduce the full model to a set of significant predictors. Compare this reduced model to the previous two models (no higher order terms and all higher order terms)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1k05Wke_B14H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2a6ef9-d398-4954-db5e-83c50defe75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No higher order: RMSE = 3.241, R² = 0.794\n",
            "All higher order: RMSE = 2.724, R² = 0.855\n",
            "Reduced (significant only): RMSE = 3.263, R² = 0.791\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sig_poly_vars = [i for i, p in enumerate(model_all_poly.pvalues[1:]) if p < 0.05]\n",
        "X_train_poly_red = X_train_poly[:, sig_poly_vars]\n",
        "X_test_poly_red = X_test_poly[:, sig_poly_vars]\n",
        "X_train_poly_red_const = sm.add_constant(X_train_poly_red)\n",
        "X_test_poly_red_const = sm.add_constant(X_test_poly_red)\n",
        "model_poly_red = sm.OLS(y_train, X_train_poly_red_const).fit()\n",
        "y_pred_poly_red = model_poly_red.predict(X_test_poly_red_const)\n",
        "rmse_poly_red = np.sqrt(mean_squared_error(y_test, y_pred_poly_red))\n",
        "r2_poly_red = r2_score(y_test, y_pred_poly_red)\n",
        "\n",
        "print(f\"No higher order: RMSE = {rmse_no_poly:.3f}, R² = {r2_no_poly:.3f}\")\n",
        "print(f\"All higher order: RMSE = {rmse_all_poly:.3f}, R² = {r2_all_poly:.3f}\")\n",
        "print(f\"Reduced (significant only): RMSE = {rmse_poly_red:.3f}, R² = {r2_poly_red:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrtIWOD6B5Z5"
      },
      "source": [
        "Part e. Explore building a model using the original variables and adding only a few important higher terms you found from the full model. Again compare this model to the others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zWdHGL-OCNTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1e683b-7068-47e6-9b61-ac519b4d0ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No higher order: RMSE = 3.241, R² = 0.794\n",
            "All higher order: RMSE = 2.724, R² = 0.855\n",
            "Reduced (significant): RMSE = 3.263, R² = 0.791\n",
            "Select terms (a few key): RMSE = 2.722, R² = 0.855\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train_select = X_train.copy()\n",
        "X_test_select = X_test.copy()\n",
        "\n",
        "# add weight squared\n",
        "X_train_select['weight_squared'] = X_train['weight'] ** 2\n",
        "X_test_select['weight_squared'] = X_test['weight'] ** 2\n",
        "\n",
        "# add displacement squared\n",
        "X_train_select['displacement_squared'] = X_train['displacement'] ** 2\n",
        "X_test_select['displacement_squared'] = X_test['displacement'] ** 2\n",
        "\n",
        "# add weight x model_year interaction\n",
        "X_train_select['weight_x_year'] = X_train['weight'] * X_train['model_year']\n",
        "X_test_select['weight_x_year'] = X_test['weight'] * X_test['model_year']\n",
        "\n",
        "X_train_select_const = sm.add_constant(X_train_select)\n",
        "X_test_select_const = sm.add_constant(X_test_select)\n",
        "model_select = sm.OLS(y_train, X_train_select_const).fit()\n",
        "y_pred_select = model_select.predict(X_test_select_const)\n",
        "rmse_select = np.sqrt(mean_squared_error(y_test, y_pred_select))\n",
        "r2_select = r2_score(y_test, y_pred_select)\n",
        "\n",
        "print(f\"No higher order: RMSE = {rmse_no_poly:.3f}, R² = {r2_no_poly:.3f}\")\n",
        "print(f\"All higher order: RMSE = {rmse_all_poly:.3f}, R² = {r2_all_poly:.3f}\")\n",
        "print(f\"Reduced (significant): RMSE = {rmse_poly_red:.3f}, R² = {r2_poly_red:.3f}\")\n",
        "print(f\"Select terms (a few key): RMSE = {rmse_select:.3f}, R² = {r2_select:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmubDEeyCNqY"
      },
      "source": [
        "**Problem 3** Use the car data and build a regression tree. Use out of sample metrics to determine the best depth for the tree. Using Feature importances, what variables are considered to be most significant. How does this compare to the linear regression model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IKb57reODHE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f673195-62d3-4cc3-9e8c-3fe0ff08bee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth\tRMSE\tR²\n",
            "1\t5.107\t0.489\n",
            "2\t4.611\t0.583\n",
            "3\t3.695\t0.733\n",
            "4\t3.416\t0.771\n",
            "5\t3.411\t0.772\n",
            "6\t3.158\t0.805\n",
            "7\t3.237\t0.795\n",
            "8\t3.196\t0.800\n",
            "9\t3.377\t0.777\n",
            "10\t3.481\t0.763\n",
            "\n",
            "Best depth: 6 with RMSE = 3.158\n",
            "\n",
            "Feature Importances:\n",
            "displacement    0.652588\n",
            "horsepower      0.175287\n",
            "model_year      0.100389\n",
            "weight          0.053929\n",
            "acceleration    0.013532\n",
            "cylinder        0.004276\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# try different depths\n",
        "best_depth = 0\n",
        "best_rmse = float('inf')\n",
        "results = []\n",
        "\n",
        "for depth in range(1, 11):\n",
        "    tree = DecisionTreeRegressor(max_depth=depth, random_state=42)\n",
        "    tree.fit(X_train, y_train)\n",
        "    y_pred_tree = tree.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_tree))\n",
        "    r2 = r2_score(y_test, y_pred_tree)\n",
        "    results.append((depth, rmse, r2))\n",
        "    if rmse < best_rmse:\n",
        "        best_rmse = rmse\n",
        "        best_depth = depth\n",
        "\n",
        "print(\"Depth\\tRMSE\\tR²\")\n",
        "for depth, rmse, r2 in results:\n",
        "    print(f\"{depth}\\t{rmse:.3f}\\t{r2:.3f}\")\n",
        "\n",
        "print(f\"\\nBest depth: {best_depth} with RMSE = {best_rmse:.3f}\")\n",
        "\n",
        "# fit best model and get feature importances\n",
        "best_tree = DecisionTreeRegressor(max_depth=best_depth, random_state=42)\n",
        "best_tree.fit(X_train, y_train)\n",
        "importances = pd.Series(best_tree.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importances:\")\n",
        "print(importances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2QM351dDGlB"
      },
      "source": [
        "The regression tree considers displacement the most important variable, followed by horsepower and model_year. In the linear regression model, weight and model_year were the most significant. Both models agree that model_year is super important! The tree picked up on displacement and horsepower being key factors, while the linear model focused more on weight."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2tKzjs5DHfn"
      },
      "source": [
        "**Problem 4**: Consider a new American car with a 6 cylinders, a displacement of 200, a horsepower of 100, a weight of 3600, an acceleration of 14, and a model year of 83."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyZAb2z9DrVg"
      },
      "source": [
        "Part a. For the best regression model in Problem 2, and the best regression tree model in Problem 3, determine the prediction for the new car."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ij7CjtD2ENsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b650402-e52e-4018-fc23-08c87d90cb8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear regression prediction: 22.79 mpg\n",
            "Regression tree prediction: 38.00 mpg\n"
          ]
        }
      ],
      "source": [
        "\n",
        "new_car_data = {\n",
        "    'const': [1.0],\n",
        "    'cylinder': [6],\n",
        "    'displacement': [200],\n",
        "    'horsepower': [100],\n",
        "    'weight': [3600],\n",
        "    'acceleration': [14],\n",
        "    'model_year': [83],\n",
        "    'weight_squared': [3600 ** 2],\n",
        "    'displacement_squared': [200 ** 2],\n",
        "    'weight_x_year': [3600 * 83]\n",
        "}\n",
        "new_car_select_const = pd.DataFrame(new_car_data)\n",
        "\n",
        "new_car_df = pd.DataFrame([[6, 200, 100, 3600, 14, 83]], columns=X.columns)\n",
        "\n",
        "pred_linear = model_select.predict(new_car_select_const)[0]\n",
        "pred_tree = best_tree.predict(new_car_df)[0]\n",
        "\n",
        "print(f\"Linear regression prediction: {pred_linear:.2f} mpg\")\n",
        "print(f\"Regression tree prediction: {pred_tree:.2f} mpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhRtwSu9EN9w"
      },
      "source": [
        "Part b. Find the confidence interval for the expected value of the prediction in the linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "c90g_HhaEWq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e0caa0-afa3-49fc-cc8b-65a5588b6f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CI for expected value: [21.30, 24.28]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ci_mean = model_select.get_prediction(new_car_select_const).conf_int()\n",
        "print(f\"CI for expected value: [{ci_mean[0,0]:.2f}, {ci_mean[0,1]:.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmFqV6bwEW6v"
      },
      "source": [
        "Part c. Find the confidence interval for the predicted value using the linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uv9v0ZRyEedI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19eaabc-c5f5-4dd8-9a0e-4401e3a05bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CI for predicted value: [16.85, 28.72]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ci_pred = model_select.get_prediction(new_car_select_const).conf_int(obs=True)\n",
        "print(f\"CI for predicted value: [{ci_pred[0,0]:.2f}, {ci_pred[0,1]:.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxCel8F4Ek8x"
      },
      "source": [
        "Part d. Explain why those confidence intervals are different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N9wvtW0EoCH"
      },
      "source": [
        "The CI for the expected value is narrower because it's estimating the average mpg for all cars with these characteristics. The CI for the predicted value is wider because it accounts for individual variation - a specific car could have better or worse fuel efficiency than the average due to random factors. Basically, predicting one specific car has more uncertainty than predicting the average!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuRGidwCErjn"
      },
      "source": [
        "Part e. Use bootstrapping to find a confidence interval for the prediction using the regression tree model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8_tdANXLSBp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3ec614-35b6-42af-d3f0-2d1e20ec8146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap CI for tree prediction: [17.67, 38.00]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "n_bootstrap = 1000\n",
        "bootstrap_preds = []\n",
        "\n",
        "for i in range(n_bootstrap):\n",
        "    indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
        "    X_boot = X_train.iloc[indices]\n",
        "    y_boot = y_train.iloc[indices]\n",
        "\n",
        "    tree_boot = DecisionTreeRegressor(max_depth=best_depth, random_state=42)\n",
        "    tree_boot.fit(X_boot, y_boot)\n",
        "    pred = tree_boot.predict(new_car_df)[0]\n",
        "    bootstrap_preds.append(pred)\n",
        "\n",
        "bootstrap_ci = np.percentile(bootstrap_preds, [2.5, 97.5])\n",
        "print(f\"Bootstrap CI for tree prediction: [{bootstrap_ci[0]:.2f}, {bootstrap_ci[1]:.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_oV_CRoE2sH"
      },
      "source": [
        "**Problem 5** Airfoils are the part of an airplane wing that allows for stability in flight due to their shape. NASA did a study of the noise level of various shapes and sizes of airfoils.  The data set for their study can be loaded using\n",
        "\n",
        "airfoil = pd.read_table(\"https://richardson.byu.edu/220/airfoil.csv\")\n",
        "\n",
        "More information on this data can be found here: https://archive.ics.uci.edu/ml/datasets/airfoil+self-noise. The target variable in the data set is labeled as Pressure. The rest are predictors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z6qtpiMFE4A"
      },
      "source": [
        "Part a. Build and tune a linear model where you scale and standardize the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qpeoEu8FFF_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d571b50-abb2-4341-9640-c975fa0a41b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Airfoil model RMSE: 4.704\n",
            "Airfoil model R²: 0.558\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression as LR\n",
        "\n",
        "# load airfoil data - use read_csv\n",
        "airfoil = pd.read_csv(\"https://richardson.byu.edu/220/airfoil.csv\")\n",
        "\n",
        "# separate features and target - last column is target\n",
        "y_air = airfoil.iloc[:, -1].values\n",
        "X_air = airfoil.iloc[:, :-1].values\n",
        "\n",
        "# train/test split\n",
        "X_air_train, X_air_test, y_air_train, y_air_test = train_test_split(X_air, y_air, test_size=0.2, random_state=42)\n",
        "\n",
        "# scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_air_train)\n",
        "X_test_scaled = scaler.transform(X_air_test)\n",
        "\n",
        "# fit the model\n",
        "model_air = LR()\n",
        "model_air.fit(X_train_scaled, y_air_train)\n",
        "\n",
        "# evaluate\n",
        "y_pred_air = model_air.predict(X_test_scaled)\n",
        "rmse_air = np.sqrt(mean_squared_error(y_air_test, y_pred_air))\n",
        "r2_air = r2_score(y_air_test, y_pred_air)\n",
        "\n",
        "print(f\"Airfoil model RMSE: {rmse_air:.3f}\")\n",
        "print(f\"Airfoil model R²: {r2_air:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxri5wIKFJTH"
      },
      "source": [
        "Part b. The manufacturing company did just build a new airfoil. They want you to use the model to predict the noise level at various velocities and frequencies. The data to predict can be found at\n",
        "\n",
        "airfoil_new = pd.read_csv(\"https://richardson.byu.edu/220/airfoil_new.csv\")\n",
        "\n",
        "Find predictions for each of the new rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xxHXuhWIFVwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1803eec-a87d-4628-f00f-6d4cf18958f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new airfoils:\n",
            "Row 1: 123.31\n",
            "Row 2: 123.23\n",
            "Row 3: 123.12\n",
            "Row 4: 122.99\n",
            "Row 5: 122.83\n",
            "Row 6: 122.61\n",
            "Row 7: 122.36\n",
            "Row 8: 122.04\n",
            "Row 9: 121.59\n",
            "Row 10: 121.09\n",
            "Row 11: 120.45\n",
            "Row 12: 119.62\n",
            "Row 13: 118.54\n",
            "Row 14: 117.27\n",
            "Row 15: 115.62\n",
            "Row 16: 113.46\n",
            "Row 17: 110.91\n",
            "Row 18: 107.73\n",
            "Row 19: 126.25\n",
            "Row 20: 126.17\n",
            "Row 21: 126.06\n",
            "Row 22: 125.93\n",
            "Row 23: 125.77\n",
            "Row 24: 125.55\n",
            "Row 25: 125.30\n",
            "Row 26: 124.98\n",
            "Row 27: 124.54\n",
            "Row 28: 124.03\n",
            "Row 29: 123.39\n",
            "Row 30: 122.56\n",
            "Row 31: 121.48\n",
            "Row 32: 120.21\n",
            "Row 33: 118.56\n",
            "Row 34: 116.40\n",
            "Row 35: 113.85\n",
            "Row 36: 110.67\n"
          ]
        }
      ],
      "source": [
        "# load new airfoil data\n",
        "airfoil_new = pd.read_csv(\"https://richardson.byu.edu/220/airfoil_new.csv\")\n",
        "\n",
        "# the original model was trained on 5 features, so use only first 5 columns\n",
        "X_new = airfoil_new.iloc[:, :5].values\n",
        "\n",
        "# scale the new data\n",
        "X_new_scaled = scaler.transform(X_new)\n",
        "\n",
        "# make predictions\n",
        "predictions = model_air.predict(X_new_scaled)\n",
        "\n",
        "print(\"Predictions for new airfoils:\")\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Row {i+1}: {pred:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCbrtfLMFWCo"
      },
      "source": [
        "Part c. The manufacturer is exploring using longer airfoil lengths than done before. They want to use lengths of 0.4 meters and they want to use your model to predict the noise level. Are there any issues with that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHO9l6P5Ff6H"
      },
      "source": [
        "Yes, there could be issues with extrapolation. If 0.4 meters is outside the range of airfoil lengths in the original training data, the model would be predicting beyond what it has seen. Linear models can be unreliable when extrapolating because the relationship might not hold outside the training range. The model was trained on certain lengths, so using it to predict for much longer airfoils could give inaccurate results since we don't know if the linear relationship continues at that length."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}